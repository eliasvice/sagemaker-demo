{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf  # pylint: disable=g-bad-import-order\n",
    "\n",
    "# from official.utils.arg_parsers import parsers\n",
    "# from official.utils.logs import hooks_helper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "_fields = [\n",
    " 'hits_hour',\n",
    " 'geonetwork_city',\n",
    " 'geonetwork_metro',\n",
    " 'device_browser',\n",
    " 'trafficsource_campaign',\n",
    " 'trafficsource_source',\n",
    " 'device_mobiledevicemodel',\n",
    " 'device_operatingsystemversion',\n",
    " 'hits_appinfo_appname',\n",
    " 'hits_appinfo_appversion',\n",
    " 'hits_appinfo_screenname',\n",
    " 'hits_page_pagetitle',\n",
    " 'hits_page_pagepath'\n",
    "]\n",
    "\n",
    "_metrics = [\n",
    "    'pageviews',\n",
    "    'screenviews',\n",
    "    'scroll_50_count',\n",
    "    'scroll_75_count',\n",
    "    'scroll_100_count'\n",
    "]\n",
    "\n",
    "_CSV_COLUMNS = _fields + _metrics\n",
    "\n",
    "_fields_defaults = [['']] * len(_fields)\n",
    "_metrics_defaults = [[0]] * len(_metrics)\n",
    "\n",
    "_target_labels_idx = {\n",
    "    '50': 0,\n",
    "    '75': 1,\n",
    "    '100': 2\n",
    "}\n",
    "\n",
    "# TODO: Select small dataset for \n",
    "_NUM_EXAMPLES = {\n",
    "    'train': 32561,\n",
    "    'validation': 16281,\n",
    "}\n",
    "\n",
    "\n",
    "LOSS_PREFIX = {'wide': 'linear/', 'deep': 'dnn/'}\n",
    "\n",
    "def build_model_columns():\n",
    "    \"\"\"\n",
    "        Builds a set of wide and deep feature columns.\n",
    "    \"\"\"\n",
    "    # Continuous columns\n",
    "\n",
    "    pageviews = tf.feature_column.numeric_column('pageviews')\n",
    "    screenviews = tf.feature_column.numeric_column('screenviews')\n",
    "\n",
    "    #     geonetwork_country = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    #         'geonetwork_country', hash_bucket_size=200\n",
    "    #     )\n",
    "    #     geonetwork_region = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    #         'geonetwork_region', hash_bucket_size=1000\n",
    "    #     )\n",
    "    \n",
    "    hits_hour = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        'hits_hour', hash_bucket_size=20\n",
    "    )\n",
    "    geonetwork_city = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        'geonetwork_city', hash_bucket_size=5000\n",
    "    )\n",
    "    geonetwork_metro = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        'geonetwork_metro', hash_bucket_size=200\n",
    "    )\n",
    "    device_browser = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        'device_browser', hash_bucket_size=50\n",
    "    )\n",
    "    trafficsource_campaign = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        'trafficsource_campaign', hash_bucket_size=3000\n",
    "    )\n",
    "    trafficsource_source = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        'trafficsource_source', hash_bucket_size=50\n",
    "    )\n",
    "    device_mobiledevicemodel = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        'device_mobiledevicemodel', hash_bucket_size=300\n",
    "    )\n",
    "    device_operatingsystemversion = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        'device_operatingsystemversion', hash_bucket_size=100\n",
    "    )\n",
    "    hits_appinfo_appname = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        'hits_appinfo_appname', hash_bucket_size=500\n",
    "    )\n",
    "    hits_appinfo_appversion = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        'hits_appinfo_appversion', hash_bucket_size=25\n",
    "    )\n",
    "    hits_appinfo_screenname = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        'hits_appinfo_screenname', hash_bucket_size=10000\n",
    "    )\n",
    "    hits_page_pagetitle = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        'hits_page_pagetitle', hash_bucket_size=15000\n",
    "    )\n",
    "    hits_page_pagepath = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        'hits_page_pagepath', hash_bucket_size=8000\n",
    "    )\n",
    "\n",
    "    # Wide columns and deep columns.\n",
    "    base_columns = [\n",
    "        pageviews, screenviews, geonetwork_city, \n",
    "        geonetwork_metro, device_browser, trafficsource_campaign, trafficsource_source, \n",
    "        device_mobiledevicemodel, device_operatingsystemversion, hits_appinfo_appname, hits_appinfo_appversion, \n",
    "        hits_appinfo_screenname, hits_page_pagetitle, hits_page_pagepath, hour_buckets, geonetwork_city, hits_hour\n",
    "    ]\n",
    "\n",
    "    crossed_columns = [\n",
    "      tf.feature_column.crossed_column(\n",
    "          ['hits_appinfo_appname', 'hits_appinfo_appversion'], hash_bucket_size=5000),\n",
    "      tf.feature_column.crossed_column(\n",
    "          ['geonetwork_city', 'hits_page_pagepath'], hash_bucket_size=25000),\n",
    "      tf.feature_column.crossed_column(\n",
    "      ['hits_hour', 'geonetwork_city'], hash_bucket_size=10000),\n",
    "    ]\n",
    "\n",
    "    wide_columns = base_columns + crossed_columns\n",
    "\n",
    "    deep_columns = [\n",
    "        pageviews,\n",
    "        screenviews,\n",
    "        tf.feature_column.embedding_column(geonetwork_metro, dimension=8),\n",
    "        tf.feature_column.embedding_column(geonetwork_city, dimension=8),\n",
    "        tf.feature_column.embedding_column(device_browser, dimension=8),\n",
    "        tf.feature_column.embedding_column(trafficsource_source, dimension=8),\n",
    "        tf.feature_column.embedding_column(trafficsource_campaign, dimension=8),\n",
    "        tf.feature_column.embedding_column(device_operatingsystemversion, dimension=8),\n",
    "        tf.feature_column.embedding_column(device_mobiledevicemodel, dimension=8),\n",
    "        tf.feature_column.embedding_column(device_language, dimension=8),\n",
    "        tf.feature_column.embedding_column(hits_appinfo_appname, dimension=8),\n",
    "        tf.feature_column.embedding_column(hits_appinfo_appversion, dimension=8),\n",
    "        tf.feature_column.embedding_column(hits_page_pagetitle, dimension=8),\n",
    "        tf.feature_column.embedding_column(hits_page_pagepath, dimension=8)\n",
    "    ]\n",
    "\n",
    "    return wide_columns, deep_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_estimator(model_dir, model_type):\n",
    "  \"\"\"Build an estimator appropriate for the given model type.\"\"\"\n",
    "  wide_columns, deep_columns = build_model_columns()\n",
    "  hidden_units = [20, 15, 10, 5]\n",
    "\n",
    "  # Create a tf.estimator.RunConfig to ensure the model is run on CPU, which\n",
    "  # trains faster than GPU for this model.\n",
    "  run_config = tf.estimator.RunConfig().replace(\n",
    "      session_config=tf.ConfigProto(device_count={'GPU': 0}))\n",
    "\n",
    "  if model_type == 'wide':\n",
    "    return tf.estimator.LinearClassifier(\n",
    "        model_dir=model_dir,\n",
    "        feature_columns=wide_columns,\n",
    "        config=run_config)\n",
    "  elif model_type == 'deep':\n",
    "    return tf.estimator.DNNClassifier(\n",
    "        model_dir=model_dir,\n",
    "        feature_columns=deep_columns,\n",
    "        hidden_units=hidden_units,\n",
    "        config=run_config)\n",
    "  else:\n",
    "    return tf.estimator.DNNLinearCombinedClassifier(\n",
    "        model_dir=model_dir,\n",
    "        linear_feature_columns=wide_columns,\n",
    "        dnn_feature_columns=deep_columns,\n",
    "        dnn_hidden_units=hidden_units,\n",
    "        config=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(data_file, num_epochs, shuffle, batch_size):\n",
    "    \"\"\"Generate an input function for the Estimator.\"\"\"\n",
    "    assert tf.gfile.Exists(data_file), (\n",
    "      '%s not found. Please make sure you have run data_download.py and '\n",
    "      'set the --data_dir argument to the correct path.' % data_file)\n",
    "\n",
    "    def parse_csv(value):\n",
    "        print('Parsing', data_file)\n",
    "        columns = tf.decode_csv(value, field_delim='|', record_defaults=_CSV_COLUMN_DEFAULTS)\n",
    "        features = dict(zip(_CSV_COLUMNS, columns))\n",
    "        labels = features.pop('article_consumption_level')\n",
    "        return features, tf.one_hot(indices=labels, depth=3)\n",
    "\n",
    "    # Extract lines from input files using the Dataset API.\n",
    "    dataset = tf.data.TextLineDataset(data_file)\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=_NUM_EXAMPLES['train'])\n",
    "\n",
    "    dataset = dataset.map(parse_csv, num_parallel_calls=3)\n",
    "\n",
    "    # We call repeat after shuffling, rather than before, to prevent separate\n",
    "    # epochs from blending together.\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "model_dir = \"./model_dir/\"\n",
    "model_type = 'wide+deep'\n",
    "data_dir = './data/'\n",
    "\n",
    "parser = WideDeepArgParser()\n",
    "flags = parser.parse_args(args=argv[1:])\n",
    "\n",
    "# Clean up the model directory if present\n",
    "shutil.rmtree(flags.model_dir, ignore_errors=True)\n",
    "\n",
    "model = build_estimator(model_dir, model_type)\n",
    "\n",
    "train_file = os.path.join(data_dir, 'scroll_traffic.train.small')\n",
    "test_file = os.path.join(data_dir, 'scroll_traffic.test.small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train and evaluate the model every `flags.epochs_between_evals` epochs.\n",
    "def train_input_fn():\n",
    "    return input_fn(\n",
    "        train_file, epochs_between_evals, True, batch_size)\n",
    "\n",
    "def eval_input_fn():\n",
    "    return input_fn(test_file, 1, False, batch_size)\n",
    "\n",
    "loss_prefix = LOSS_PREFIX.get(model_type, '')\n",
    "train_hooks = hooks_helper.get_train_hooks(\n",
    "  hooks, batch_size=batch_size,\n",
    "  tensors_to_log={'average_loss': loss_prefix + 'head/truediv',\n",
    "                  'loss': loss_prefix + 'head/weighted_loss/Sum'})\n",
    "\n",
    "# Train and evaluate the model every `flags.epochs_between_evals` epochs.\n",
    "for n in range(flags.train_epochs // flags.epochs_between_evals):\n",
    "    model.train(input_fn=train_input_fn, hooks=train_hooks)\n",
    "    results = model.evaluate(input_fn=eval_input_fn)\n",
    "\n",
    "    # Display evaluation metrics\n",
    "    print('Results at epoch', (n + 1) * epochs_between_evals)\n",
    "    print('-' * 60)\n",
    "\n",
    "    for key in sorted(results):\n",
    "        print('%s: %s' % (key, results[key]))\n",
    "\n",
    "    if model_helpers.past_stop_threshold(\n",
    "        stop_threshold, results['accuracy']):\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
